{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/thro.png\" align=\"right\"> \n",
    "# A2I2 - Artificial Neural Networks (ANN)\n",
    "\n",
    "## Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Modeling and Evaluation (Cost-Benefit-Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us revisit our Cardiotocography Evaluation project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Business Problem: </span> Cardiotocography Evaluation\n",
    "\n",
    "During pregnancy, many doctors perform \"fetal cardiotocograms\", recording the heartbeat and other measurements of the fetus in order to assess fetal wellbeing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Understanding the business</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cardiotocography**\n",
    "* The recorded data is quite hard to interpret, ideally a group if experts is doing the evaluation. However, quite often, this is not possible and a single doctor has to do the interpretation alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Mapping to Data Science Problems and Methods</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Automatically interpret cardiotocography data to assess fetal health (classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Modeling and Evaluation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we evaluate **from a business perspective** if our (as of now not existing) model solves the **business problem**?\n",
    "\n",
    "You know about accuracy, the confusion matrix and many other classification evaluation techniques. But how do we apply these to a business problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cost-Benefit-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**Cost–benefit analysis (CBA)**, sometimes also called benefit–cost analysis or benefit costs analysis, is a systematic approach to estimating the strengths and weaknesses of alternatives used to determine options which provide the best approach to achieving benefits while preserving savings (for example, in transactions, activities, and functional business requirements). A CBA may be used to compare completed or potential courses of actions, or to estimate (or evaluate) the value against the cost of a decision, project, or policy. It is commonly used in commercial transactions, business or policy decisions (particularly public policy), and project investments.\" \n",
    "(<a href=\"https://en.wikipedia.org/wiki/Cost%E2%80%93benefit_analysis\">wikipedia</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the confusion Matrix: \n",
    "\n",
    "$$\\begin{bmatrix}\n",
    " & Predicted-Negative & Predicted-Positive\\\\\n",
    "True-Condition-Negative & TN & FP\\\\\n",
    "True-Condition-Positive & FN & TP \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We can assign now a **cost or benefit** to each sample, that is classified (TN, FP, FN, TP) based on the **business problem**!\n",
    "\n",
    "In our example, we have three classes: NSP = fetal state class code (1=normal; 2=suspect; 3=pathologic), leading to a confusion matrix:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    " & Predicted-0 & Predicted-1 & Predicted-2\\\\\n",
    "True-Condition-0 & NN & NS & NP \\\\\n",
    "True-Condition-1 & SN & SS & SP \\\\\n",
    "True-Condition-2 & PN & PS & PP \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We need to assing a cost or benefit to each of these 9 possible outcomes as a financial value. Let us try to put a cost on each case, and afterward minimize this cost. Let us assume that a pathologic fetus can be treated, if diagnosed as pathologic. If a pathologic fetus is not diagnosed and therefore not treated, let us assume this will be diagnosed at the next examination but lead to a more expensive treatment with an additional cost of 20.000. Let us also assume that a suspected or pathologic diagnosis is verified with an additional test costing 1000.\n",
    "\n",
    "* NN (truly normal,  predicted normal): cost 0\n",
    "* NS (truly normal, predicted suspect): further (unnecessary) test need to be conducted leading to a cost of 1000\n",
    "* NP (truly normal, predicted pathologic): further (unnecessary) test need to be conducted, leading to a cost of 1000\n",
    "\n",
    "* SN (truly suspect, predicted normal): this is hard to quantifiy - let us assume, that 50% of the suspect cases in reality are healthy, so by making this error, we actually save 1000. The other 50% are pathologic and remain untreated costing 20.000. So this error leads to a cost of (20.000 - 1000)/2 = 9.500\n",
    "* SS (truly suspect, predicted suspect): further (necessary) test will be conducted, cost 0\n",
    "* SP (truly suspect, predicted pathologic): further (necessary) test will be conducted, cost 0\n",
    "\n",
    "* PN (truly pathologic, predicted normal): will remain untreated costing 20000\n",
    "* PS (truly pathologic but predicted suspect): further (necessary) test will be conducted, cost 0\n",
    "* PP (truly pathologic but predicted pathologic): further (necessary) test will be conducted, cost 0\n",
    "\n",
    "This leads to the following cost-benefit-matrix:\n",
    "$$\\begin{bmatrix}\n",
    " & Predicted-0 & Predicted-1 & Predicted-2\\\\\n",
    "True-Condition-0 & 0 & 1000 & 1000 \\\\\n",
    "True-Condition-1 & 9500 & 0 & 0 \\\\\n",
    "True-Condition-2 & 20000 & 0 & 0 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "***We can now weigh the confusion matrix by the cost-benefit matrix to evalute a classification model from a business perspective.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply to this our (full, no outlier removal) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB    AC   FM    UC   DL   DS   DP  ASTV  MSTV  ALTV  ...    Min  \\\n",
       "0     120.0  0.00  0.0  0.00  0.0  0.0  0.0  73.0   0.5  43.0  ...   62.0   \n",
       "1     132.0  0.01  0.0  0.01  0.0  0.0  0.0  17.0   2.1   0.0  ...   68.0   \n",
       "2     133.0  0.00  0.0  0.01  0.0  0.0  0.0  16.0   2.1   0.0  ...   68.0   \n",
       "3     134.0  0.00  0.0  0.01  0.0  0.0  0.0  16.0   2.4   0.0  ...   53.0   \n",
       "4     132.0  0.01  0.0  0.01  0.0  0.0  0.0  16.0   2.4   0.0  ...   53.0   \n",
       "...     ...   ...  ...   ...  ...  ...  ...   ...   ...   ...  ...    ...   \n",
       "2121  140.0  0.00  0.0  0.01  0.0  0.0  0.0  79.0   0.2  25.0  ...  137.0   \n",
       "2122  140.0  0.00  0.0  0.01  0.0  0.0  0.0  78.0   0.4  22.0  ...  103.0   \n",
       "2123  140.0  0.00  0.0  0.01  0.0  0.0  0.0  79.0   0.4  20.0  ...  103.0   \n",
       "2124  140.0  0.00  0.0  0.01  0.0  0.0  0.0  78.0   0.4  27.0  ...  103.0   \n",
       "2125  142.0  0.00  0.0  0.01  0.0  0.0  0.0  74.0   0.4  36.0  ...  117.0   \n",
       "\n",
       "        Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "0     126.0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "1     198.0   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "2     198.0   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "3     170.0  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "4     170.0   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
       "...     ...   ...     ...    ...    ...     ...       ...       ...  ...  \n",
       "2121  177.0   4.0     0.0  153.0  150.0   152.0       2.0       0.0  2.0  \n",
       "2122  169.0   6.0     0.0  152.0  148.0   151.0       3.0       1.0  2.0  \n",
       "2123  170.0   5.0     0.0  153.0  148.0   152.0       4.0       1.0  2.0  \n",
       "2124  169.0   6.0     0.0  152.0  147.0   151.0       4.0       1.0  2.0  \n",
       "2125  159.0   2.0     1.0  145.0  143.0   145.0       1.0       0.0  1.0  \n",
       "\n",
       "[2126 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_raw = pd.read_csv('data/CTG.csv', delimiter=';', decimal=\",\")\n",
    "ctg_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = ['ALTV', 'ASTV', 'LB', 'MLTV', 'MSTV', 'Max', 'Mean', \n",
    "                   'Median', 'Min', 'Mode', 'Nmax', 'Variance', 'Width'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ctg_raw[used_features]\n",
    "y = ctg_raw['NSP']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: accuracy on train = 0.999328 and on test = 0.913793\n"
     ]
    }
   ],
   "source": [
    "# let's look at the (plain) accuracy first, it is returned by the 'score' method\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "score_train = classifier.score(X_train, y_train)\n",
    "score_test = classifier.score(X_test, y_test)\n",
    "print('DT: accuracy on train = %f and on test = %f' % (score_train, score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix on Training Data: \n",
      "[[1165    0    0]\n",
      " [   1  198    0]\n",
      " [   0    0  124]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[471  14   5]\n",
      " [ 28  65   3]\n",
      " [  3   2  47]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = classifier.predict(X_train)\n",
    "cfm_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Confusion Matrix on Training Data: \")\n",
    "print(cfm_train)\n",
    "\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "cfm_test = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix on Test Data: \")\n",
    "print(cfm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1000, 1000], [9500, 0, 0], [20000, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the cost-benefit-matrix\n",
    "cbm = [[0, 1000, 1000], [9500, 0, 0], [20000, 0, 0]]\n",
    "cbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cost on the test data per examination: 540.75€\n"
     ]
    }
   ],
   "source": [
    "# simply multiply the confusion matrix by the cost/benefits and divide by the number\n",
    "# of examinations in the test set\n",
    "expected_cost = (cfm_test*cbm).sum()/cfm_test.sum()\n",
    "print('Expected cost on the test data per examination: %.2f€' %(expected_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare this to a couple of other classifiers\n",
    "def eval(name, classifier, X_train, y_train, X_test, y_test, cbm): \n",
    "    classifier.fit(X_train, y_train)\n",
    "    score_train = classifier.score(X_train, y_train)\n",
    "    score_test = classifier.score(X_test, y_test)\n",
    "    print('Evaluating %s' % (name))\n",
    "    print('Accuracy on train = %f and on test = %f' % (score_train, score_test))\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    cfm_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "    print(\"Confusion Matrix on Training Data: \")\n",
    "    print(cfm_train)\n",
    "\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    cfm_test = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "    print(\"Confusion Matrix on Test Data: \")\n",
    "    print(cfm_test)\n",
    "\n",
    "    expected_cost = (cfm_test*cbm).sum()/cfm_test.sum()\n",
    "    print('Expected result on the test data per sample: %.2f€' %(expected_cost))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating logistic Regression\n",
      "Accuracy on train = 0.890457 and on test = 0.866771\n",
      "Confusion Matrix on Training Data: \n",
      "[[1121   32   12]\n",
      " [  88  105    6]\n",
      " [  11   14   99]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[470  16   4]\n",
      " [ 44  47   5]\n",
      " [  5  11  36]]\n",
      "Expected result on the test data per sample: 843.26€\n",
      "\n",
      "Evaluating SVM\n",
      "Accuracy on train = 0.890457 and on test = 0.873041\n",
      "Confusion Matrix on Training Data: \n",
      "[[1118   38    9]\n",
      " [  82  109    8]\n",
      " [  13   13   98]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[470  18   2]\n",
      " [ 36  50  10]\n",
      " [  4  11  37]]\n",
      "Expected result on the test data per sample: 692.79€\n",
      "\n",
      "Evaluating Gradient Boosting\n",
      "Accuracy on train = 0.985887 and on test = 0.942006\n",
      "Confusion Matrix on Training Data: \n",
      "[[1162    3    0]\n",
      " [  17  182    0]\n",
      " [   1    0  123]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[481   6   3]\n",
      " [ 23  71   2]\n",
      " [  2   1  49]]\n",
      "Expected result on the test data per sample: 419.28€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression (this is a classifier, the name is just badly choosen!)\n",
    "eval('logistic Regression', LogisticRegression(solver=\"lbfgs\", max_iter=10000), \n",
    "     X_train, y_train, X_test, y_test, cbm)\n",
    "# Support Vector Machine\n",
    "eval('SVM', SVC(kernel=\"linear\"), \n",
    "     X_train, y_train, X_test, y_test, cbm)\n",
    "# Gradient Boosting\n",
    "eval('Gradient Boosting', GradientBoostingClassifier(), \n",
    "     X_train, y_train, X_test, y_test, cbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a few neural networks - using MLPClassifier\n",
    "# Let us use SGD as the solver with an adaptive learning rate (and moments)\n",
    "# and a mini-batch size of 64. For SGD, the max_iter specified the number of epochs, 1000 should be plenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EOF ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
