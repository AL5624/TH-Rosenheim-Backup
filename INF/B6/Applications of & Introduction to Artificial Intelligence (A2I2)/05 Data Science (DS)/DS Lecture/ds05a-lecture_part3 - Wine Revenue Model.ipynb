{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/thro.png\" align=\"right\"> \n",
    "# A2I2 - Artificial Neural Networks (ANN)\n",
    "\n",
    "## <span style=\"color:red\">Lecture - Part 3 - Exercise Solution</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Modeling and Evaluation (Cost-Benefit-Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Reminder</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Business Problem: </span> Optimize wine revenue\n",
    "\n",
    "Wine can have different quality - better wines are more expensive than average or below average wines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Understanding the business</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wine Making**\n",
    "* Wine is made from grapes.\n",
    "* Price of the wine depends on the **expected** quality about 5 to 10 years after production.\n",
    "* Two options: \n",
    "    * keep wine until the quality is known and sell for \"correct\" price -> lots of storage needed\n",
    "    * estimate quality and sell immediately  \n",
    "* Many chemical attributes of the (newly made) wine can be measured easily (e.g. acidity, sugar, pH, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Mapping to Data Science Problems and Methods</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict wine quality based on measured attributes (classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Discussion</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your data science problem above is still very soft and not specific enough to easily come up with a cost-benefit matrix. What will our business user do with the predicted quality? Let us assume that the exact price of a quality cannot be estimated as it depends on many other factors as well. \n",
    "\n",
    "A much better wording of the business problem could be: The winery has decided that the best usage of the restricted storage space is to store all batches of wines with a quality of at least 7 and sell them after five years. They expect to earn an additional 30.000 EUR as compared to selling the wine immediately. All wines with quality of 6 and below will be sold immediately as the expectations is that the price will only increas by 500 EUR per batch. Storing a batch of wine costs 10.000 EUR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Your Job</span>\n",
    "\n",
    "a) Re-Define the data science problem and the method to use\n",
    "\n",
    "b) Build multiple models and evalute them\n",
    "\n",
    "c) Recommend the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval function copied from the code in the lecture\n",
    "def eval(name, classifier, X_train, y_train, X_test, y_test, cbm): \n",
    "    classifier.fit(X_train, y_train)\n",
    "    score_train = classifier.score(X_train, y_train)\n",
    "    score_test = classifier.score(X_test, y_test)\n",
    "    print('Evaluating %s' % (name))\n",
    "    print('Accuracy on train = %f and on test = %f' % (score_train, score_test))\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    cfm_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "    print(\"Confusion Matrix on Training Data: \")\n",
    "    print(cfm_train)\n",
    "\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    cfm_test = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "    print(\"Confusion Matrix on Test Data: \")\n",
    "    print(cfm_test)\n",
    "\n",
    "    expected_cost = (cfm_test*cbm).sum()/cfm_test.sum()\n",
    "    print('Expected result on the test data per sample: %.2fâ‚¬' %(expected_cost))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Data Science Problem and method**\n",
    "\n",
    "Predict if a wine is quality 7 or above (the positive case) or quality 6 and below (the negative case) using classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) CBM, modeling and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4812 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  target  \n",
       "0         8.8        6       0  \n",
       "1         9.5        6       0  \n",
       "2        10.1        6       0  \n",
       "3         9.9        6       0  \n",
       "4         9.9        6       0  \n",
       "...       ...      ...     ...  \n",
       "4893     11.2        6       0  \n",
       "4894      9.6        5       0  \n",
       "4895      9.4        6       0  \n",
       "4896     12.8        7       1  \n",
       "4897     11.8        6       0  \n",
       "\n",
       "[4812 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and clean the data\n",
    "wine_raw = pd.read_csv('data/winequality-white.csv', delimiter=';')\n",
    "wine_raw['target'] = (wine_raw['quality'] >= 7.0).astype(int)\n",
    "wine_is_outlier_attribute = (np.abs(wine_raw - np.mean(wine_raw)) > np.std(wine_raw)*5)\n",
    "wine_is_outlier_tupel = wine_is_outlier_attribute.any(axis=1)\n",
    "wine = wine_raw[-wine_is_outlier_tupel]\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3753\n",
       "1    1059\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'pH',\n",
       " 'density',\n",
       " 'free sulfur dioxide',\n",
       " 'citric acid',\n",
       " 'total sulfur dioxide',\n",
       " 'residual sugar',\n",
       " 'volatile acidity',\n",
       " 'chlorides',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_features = list(set(wine.columns) - set(['quality', 'target']))\n",
    "used_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine[used_features]\n",
    "y = wine['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix / Cost-Benefit-Matrix: \n",
    "\n",
    "$$\\begin{bmatrix}\n",
    " & Predicted-Negative & Predicted-Positive\\\\\n",
    "True-Condition-Negative & TN & FP\\\\\n",
    "True-Condition-Positive & FN & TP \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "* TN (truly bad quality, predicted bad quality): benefit 500\n",
    "* FP (truly bad quality, predicted good quality): benefit 500-10.000 = -9.500\n",
    "\n",
    "* FN (truly good quality, predicted bad quality): benefit 500\n",
    "* TP (truly good quality, predicted good quality): benefit 30.000 - 10.000 = 20.000\n",
    "\n",
    "Note that we are not account for \"lost opportunities\" - if we would account for this, we would count these revenues twice. This is very important! Think about a good quality wine. If one classifiers classifies ist as bad, we get a benefit of 500EUR. If the other classifier classifies it as good, we get a benefit of 20.000EUR  - so the missclassification costs us 19.500 EUR. If we put the -19.500 EUR as value for FN in the CBM, we would \"gain\" 38.000 EUR by changing this classification - which clearly is wrong. This is one of the most widespread and dangerous mistakes when setting up a CBM!\n",
    "\n",
    "This leads to the following cost-benefit-matrix:\n",
    "$$\\begin{bmatrix}\n",
    " & Predicted-Negative & Predicted-Positive\\\\\n",
    "True-Condition-Negative & 500 & -9.500\\\\\n",
    "True-Condition-Positive & 500 & +20.000 \\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[500, -9500], [500, 20000]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the cost-benefit-matrix\n",
    "cbm = [[500, -9500], [500, 20000]]\n",
    "cbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree\n",
      "Accuracy on train = 1.000000 and on test = 0.822715\n",
      "Confusion Matrix on Training Data: \n",
      "[[2592    0]\n",
      " [   0  776]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[1002  159]\n",
      " [  97  186]]\n",
      "Expected result on the test data per sample: 1910.66â‚¬\n",
      "\n",
      "Evaluating logistic Regression\n",
      "Accuracy on train = 0.792755 and on test = 0.819252\n",
      "Confusion Matrix on Training Data: \n",
      "[[2459  133]\n",
      " [ 565  211]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[1105   56]\n",
      " [ 205   78]]\n",
      "Expected result on the test data per sample: 1165.51â‚¬\n",
      "\n",
      "Evaluating SVM\n",
      "Accuracy on train = 0.769596 and on test = 0.804017\n",
      "Confusion Matrix on Training Data: \n",
      "[[2592    0]\n",
      " [ 776    0]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[1161    0]\n",
      " [ 283    0]]\n",
      "Expected result on the test data per sample: 500.00â‚¬\n",
      "\n",
      "Evaluating Gradient Boosting\n",
      "Accuracy on train = 0.861936 and on test = 0.851801\n",
      "Confusion Matrix on Training Data: \n",
      "[[2474  118]\n",
      " [ 347  429]]\n",
      "Confusion Matrix on Test Data: \n",
      "[[1095   66]\n",
      " [ 148  135]]\n",
      "Expected result on the test data per sample: 1866.00â‚¬\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "eval('Decision Tree', DecisionTreeClassifier(random_state=42), \n",
    "     X_train, y_train, X_test, y_test, cbm)\n",
    "# logistic regression (this is a classifier, the name is just badly choosen!)\n",
    "eval('logistic Regression', LogisticRegression(solver=\"lbfgs\", max_iter=10000), \n",
    "     X_train, y_train, X_test, y_test, cbm)\n",
    "# Support Vector Machine\n",
    "eval('SVM', SVC(kernel=\"rbf\"), \n",
    "     X_train, y_train, X_test, y_test, cbm)\n",
    "# Gradient Boosting\n",
    "eval('Gradient Boosting', GradientBoostingClassifier(), \n",
    "     X_train, y_train, X_test, y_test, cbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: The Decision Tree is clearly overfitting (accuracy on training data = 100%, accuracy on test data = 82%). Gradient boosting has the best accuracy on test (85%), however, it is outperfomed by the (overfitting) decision tree when evaluating the cost-benefit (you may get slightly different results as there is some randomness involved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a few neural networks - using MLPClassifier\n",
    "# Let us use SGD as the solver with an adaptive learning rate (and moments)\n",
    "# and a mini-batch size of 64. For SGD, the max_iter specified the number of epochs, 1000 should be plenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EOF ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
