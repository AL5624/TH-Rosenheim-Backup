{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/thro.png\" align=\"right\"> \n",
    "# # A2I2 - Natural Language Processing (NLP)\n",
    "\n",
    "## <span style=\"color:red\">Lecture - Part 1: Preprocessing</span>\n",
    "\n",
    "## <span style=\"color:red\">Exercise Solution</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/webtext.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('webtext')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise for Part 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise we will be looking at a corpus of twitter tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain £170 billion per year! #BetterOffOut #UKIP',\n",
       " 'VIDEO: Sturgeon on post-election deals http://t.co/BTJwrpbmOY',\n",
       " 'RT @LabourEoin: The economy was growing 3 times faster on the day David Cameron became Prime Minister than it is today.. #BBCqt http://t.co…',\n",
       " 'RT @GregLauder: the UKIP east lothian candidate looks about 16 and still has an msn addy http://t.co/7eIU0c5Fm1',\n",
       " \"RT @thesundaypeople: UKIP's housing spokesman rakes in £800k in housing benefit from migrants.  http://t.co/GVwb9Rcb4w http://t.co/c1AZxcLh…\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweets_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RT',\n",
       "  '@KirkKus',\n",
       "  ':',\n",
       "  'Indirect',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'the',\n",
       "  'UK',\n",
       "  'being',\n",
       "  'in',\n",
       "  'the',\n",
       "  'EU',\n",
       "  'is',\n",
       "  'estimated',\n",
       "  'to',\n",
       "  'be',\n",
       "  'costing',\n",
       "  'Britain',\n",
       "  '£',\n",
       "  '170',\n",
       "  'billion',\n",
       "  'per',\n",
       "  'year',\n",
       "  '!',\n",
       "  '#BetterOffOut',\n",
       "  '#UKIP'],\n",
       " ['VIDEO',\n",
       "  ':',\n",
       "  'Sturgeon',\n",
       "  'on',\n",
       "  'post-election',\n",
       "  'deals',\n",
       "  'http://t.co/BTJwrpbmOY'],\n",
       " ['RT',\n",
       "  '@LabourEoin',\n",
       "  ':',\n",
       "  'The',\n",
       "  'economy',\n",
       "  'was',\n",
       "  'growing',\n",
       "  '3',\n",
       "  'times',\n",
       "  'faster',\n",
       "  'on',\n",
       "  'the',\n",
       "  'day',\n",
       "  'David',\n",
       "  'Cameron',\n",
       "  'became',\n",
       "  'Prime',\n",
       "  'Minister',\n",
       "  'than',\n",
       "  'it',\n",
       "  'is',\n",
       "  'today',\n",
       "  '..',\n",
       "  '#BBCqt',\n",
       "  'http://t.co…']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default tokenizer for Tweets is specialised for 'casual' text, and the \n",
    "# tokenized() method returns a list of lists of tokens.\n",
    "tweets_tok = twitter_samples.tokenized('tweets.20150430-223406.json')\n",
    "tweets_tok[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Preprocess this corpus of twitter tweets!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lower case (downloading and tokenization has already been done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rt',\n",
       "  '@kirkkus',\n",
       "  ':',\n",
       "  'indirect',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'the',\n",
       "  'uk',\n",
       "  'being',\n",
       "  'in',\n",
       "  'the',\n",
       "  'eu',\n",
       "  'is',\n",
       "  'estimated',\n",
       "  'to',\n",
       "  'be',\n",
       "  'costing',\n",
       "  'britain',\n",
       "  '£',\n",
       "  '170',\n",
       "  'billion',\n",
       "  'per',\n",
       "  'year',\n",
       "  '!',\n",
       "  '#betteroffout',\n",
       "  '#ukip'],\n",
       " ['video',\n",
       "  ':',\n",
       "  'sturgeon',\n",
       "  'on',\n",
       "  'post-election',\n",
       "  'deals',\n",
       "  'http://t.co/btjwrpbmoy'],\n",
       " ['rt',\n",
       "  '@laboureoin',\n",
       "  ':',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'was',\n",
       "  'growing',\n",
       "  '3',\n",
       "  'times',\n",
       "  'faster',\n",
       "  'on',\n",
       "  'the',\n",
       "  'day',\n",
       "  'david',\n",
       "  'cameron',\n",
       "  'became',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'than',\n",
       "  'it',\n",
       "  'is',\n",
       "  'today',\n",
       "  '..',\n",
       "  '#bbcqt',\n",
       "  'http://t.co…']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_lc = [[token.lower() for token in tweet] for tweet in tweets_tok]\n",
    "tweets_lc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords (incl. special stopwords for tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# we see a lot of stop words, so let's remove these\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "tweets_nsw1 = [[word for word in tweet if not word in sw] for tweet in tweets_lc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rt',\n",
       "  '@kirkkus',\n",
       "  ':',\n",
       "  'indirect',\n",
       "  'cost',\n",
       "  'uk',\n",
       "  'eu',\n",
       "  'estimated',\n",
       "  'costing',\n",
       "  'britain',\n",
       "  '£',\n",
       "  '170',\n",
       "  'billion',\n",
       "  'per',\n",
       "  'year',\n",
       "  '!',\n",
       "  '#betteroffout',\n",
       "  '#ukip'],\n",
       " ['video',\n",
       "  ':',\n",
       "  'sturgeon',\n",
       "  'post-election',\n",
       "  'deals',\n",
       "  'http://t.co/btjwrpbmoy'],\n",
       " ['rt',\n",
       "  '@laboureoin',\n",
       "  ':',\n",
       "  'economy',\n",
       "  'growing',\n",
       "  '3',\n",
       "  'times',\n",
       "  'faster',\n",
       "  'day',\n",
       "  'david',\n",
       "  'cameron',\n",
       "  'became',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'today',\n",
       "  '..',\n",
       "  '#bbcqt',\n",
       "  'http://t.co…']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nsw1[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 20225 samples and 322813 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(':', 16631),\n",
       " ('rt', 13540),\n",
       " ('.', 12588),\n",
       " (',', 7546),\n",
       " ('…', 6371),\n",
       " ('miliband', 5318),\n",
       " ('snp', 4611),\n",
       " ('\"', 4270),\n",
       " ('tories', 4112),\n",
       " ('ed', 2812),\n",
       " ('labour', 2624),\n",
       " ('#bbcqt', 2617),\n",
       " ('-', 2574),\n",
       " ('cameron', 2468),\n",
       " ('?', 2332),\n",
       " (\"'\", 2321),\n",
       " ('%', 2284),\n",
       " ('!', 1916),\n",
       " ('farage', 1823),\n",
       " ('ukip', 1773),\n",
       " ('tory', 1748),\n",
       " ('...', 1725),\n",
       " ('david', 1697),\n",
       " ('rather', 1537),\n",
       " ('vote', 1465),\n",
       " ('would', 1355),\n",
       " ('let', 1320),\n",
       " ('/', 1231),\n",
       " ('deal', 1227),\n",
       " ('(', 1198),\n",
       " ('&', 1182),\n",
       " ('#asknigelfarage', 1176),\n",
       " ('#ukip', 1125),\n",
       " ('http', 1104),\n",
       " (')', 1050),\n",
       " ('work', 1039),\n",
       " ('clegg', 1001),\n",
       " ('nigel', 984),\n",
       " ('support', 944),\n",
       " ('tonight', 927),\n",
       " ('people', 891),\n",
       " ('scotland', 847),\n",
       " ('lab', 838),\n",
       " ('going', 821),\n",
       " ('leader', 817),\n",
       " ('says', 812),\n",
       " ('w', 807),\n",
       " ('come', 787),\n",
       " ('man', 784),\n",
       " ('claiming', 772)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist([token for tweet in tweets_nsw1 for token in tweet])\n",
    "print(fdist)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 20189 samples and 236064 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('miliband', 5318),\n",
       " ('snp', 4611),\n",
       " ('tories', 4112),\n",
       " ('ed', 2812),\n",
       " ('labour', 2624),\n",
       " ('#bbcqt', 2617),\n",
       " ('cameron', 2468),\n",
       " ('farage', 1823),\n",
       " ('ukip', 1773),\n",
       " ('tory', 1748),\n",
       " ('david', 1697),\n",
       " ('rather', 1537),\n",
       " ('vote', 1465),\n",
       " ('would', 1355),\n",
       " ('let', 1320),\n",
       " ('deal', 1227),\n",
       " ('#asknigelfarage', 1176),\n",
       " ('#ukip', 1125),\n",
       " ('work', 1039),\n",
       " ('clegg', 1001),\n",
       " ('nigel', 984),\n",
       " ('support', 944),\n",
       " ('tonight', 927),\n",
       " ('people', 891),\n",
       " ('scotland', 847),\n",
       " ('lab', 838),\n",
       " ('going', 821),\n",
       " ('leader', 817),\n",
       " ('says', 812),\n",
       " ('come', 787),\n",
       " ('man', 784),\n",
       " ('claiming', 772),\n",
       " ('time', 721),\n",
       " ('#snp', 709),\n",
       " ('get', 696),\n",
       " ('@ukip', 695),\n",
       " ('@ed_miliband', 694),\n",
       " ('mps', 692),\n",
       " ('need', 688),\n",
       " ('times', 678),\n",
       " ('@nigel_farage', 674),\n",
       " ('like', 674),\n",
       " ('#ge2015', 658),\n",
       " ('wrote', 644),\n",
       " ('financial', 642),\n",
       " ('inequality', 641),\n",
       " ('preoccupied', 637),\n",
       " ('@nicolasturgeon', 636),\n",
       " ('want', 634),\n",
       " ('@tommy_colc', 632),\n",
       " ('audience', 587),\n",
       " ('government', 582),\n",
       " ('one', 561),\n",
       " ('sturgeon', 556),\n",
       " ('say', 554),\n",
       " ('said', 550),\n",
       " ('well', 541),\n",
       " ('think', 534),\n",
       " ('uk', 532),\n",
       " ('milliband', 530),\n",
       " ('question', 521),\n",
       " ('nick', 503),\n",
       " ('poll', 499),\n",
       " ('party', 493),\n",
       " ('bbc', 487),\n",
       " ('back', 482),\n",
       " ('ft', 476),\n",
       " ('sco', 471),\n",
       " ('definitely', 470),\n",
       " ('protect', 453),\n",
       " ('lots', 450),\n",
       " ('con', 447),\n",
       " ('pm', 435),\n",
       " ('govt', 435),\n",
       " ('election', 412),\n",
       " ('voting', 406),\n",
       " ('even', 404),\n",
       " ('scottish', 403),\n",
       " ('next', 395),\n",
       " ('us', 394),\n",
       " ('power', 393),\n",
       " ('debate', 381),\n",
       " ('nicola', 370),\n",
       " ('see', 370),\n",
       " ('years', 369),\n",
       " ('never', 359),\n",
       " ('coalition', 352),\n",
       " ('saying', 339),\n",
       " ('eu', 330),\n",
       " ('tax', 327),\n",
       " ('could', 323),\n",
       " ('voters', 323),\n",
       " ('make', 322),\n",
       " ('right', 318),\n",
       " ('last', 315),\n",
       " ('benefit', 307),\n",
       " ('@laboureoin', 295),\n",
       " ('#votesnp', 293),\n",
       " ('retweet', 293),\n",
       " ('questions', 291)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_sw = [':', 'rt', '.', ',', '…', '\"', '-', '?', \"'\", '%', '!', '...', '/', '(', '&', 'http', ')', 'w', \n",
    "              '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', ':/', '’', '*', '+', '..', \"i'm\", \"he's\" , \"he'd\"]\n",
    "tweets_nsw2 = [[word for word in tweet if not word in twitter_sw] for tweet in tweets_nsw1]\n",
    "fdist = nltk.FreqDist([token for tweet in tweets_nsw2 for token in tweet])\n",
    "print(fdist)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could go through more words and remove even more stopwords, but let's leave it at this for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tweets_lem = [[wordnet_lemmatizer.lemmatize(word) for word in tweet] for tweet in tweets_nsw2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19259 samples and 236064 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tory', 5863),\n",
       " ('miliband', 5318),\n",
       " ('snp', 4615),\n",
       " ('ed', 2814),\n",
       " ('labour', 2651),\n",
       " ('#bbcqt', 2617),\n",
       " ('cameron', 2468),\n",
       " ('farage', 1823),\n",
       " ('ukip', 1773),\n",
       " ('david', 1697),\n",
       " ('vote', 1577),\n",
       " ('rather', 1537),\n",
       " ('deal', 1443),\n",
       " ('time', 1399),\n",
       " ('say', 1366),\n",
       " ('would', 1355),\n",
       " ('let', 1347),\n",
       " ('#asknigelfarage', 1176),\n",
       " ('#ukip', 1125),\n",
       " ('work', 1100),\n",
       " ('clegg', 1001),\n",
       " ('leader', 991),\n",
       " ('nigel', 984),\n",
       " ('support', 948),\n",
       " ('tonight', 945),\n",
       " ('people', 909),\n",
       " ('scotland', 853),\n",
       " ('lab', 840),\n",
       " ('come', 832),\n",
       " ('going', 821),\n",
       " ('question', 812),\n",
       " ('man', 787),\n",
       " ('get', 780),\n",
       " ('want', 772),\n",
       " ('claiming', 772),\n",
       " ('mp', 744),\n",
       " ('need', 736),\n",
       " ('#snp', 709),\n",
       " ('@ukip', 695),\n",
       " ('@ed_miliband', 694),\n",
       " ('like', 690),\n",
       " ('@nigel_farage', 674),\n",
       " ('#ge2015', 658),\n",
       " ('wrote', 644),\n",
       " ('financial', 642),\n",
       " ('inequality', 641),\n",
       " ('preoccupied', 637),\n",
       " ('@nicolasturgeon', 636),\n",
       " ('@tommy_colc', 632),\n",
       " ('poll', 604)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist([token for tweet in tweets_lem for token in tweet])\n",
    "print(fdist)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that for example question and questions have been combined, as have saying and say"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, write the lemmatized tweets into a file so we can re-use it in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tweets_lem.data', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(tweets_lem, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
